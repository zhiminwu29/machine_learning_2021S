knitr::opts_chunk$set(echo = TRUE)
cd = read.csv("http://www.rob-mcculloch.org/data/usedcars.csv")
print(dim(cd))
head(cd)
library(glmnet)
#dummy up the categorical variables
cd$trim=as.factor(cd$trim)
cd$isOneOwner=as.factor(cd$isOneOwner)
cd$color=as.factor(cd$color)
cd$displacement=as.factor(cd$displacement)
cd$fuel=as.factor(cd$fuel)
cd$region=as.factor(cd$region)
cd$soundSystem=as.factor(cd$soundSystem)
cd$wheelType=as.factor(cd$wheelType)
summary(cd)
## Get the model matrix (x) and log price (y)
x=model.matrix(log(price)~.,cd)[,-1]
x=scale(x) #let's scale the data to start with so we an interpret stuff.
y=log(cd$price)
print(dim(x))
print(colnames(x))
## do lasso (alpha=1)
gsize=100
grid=5^seq(10,-2,length=gsize)
lasso.mod=glmnet(x,y,alpha=1,lambda=grid,standardize=FALSE)
## plot coefficients
cmat = coef(lasso.mod)
cmat = cmat[2:nrow(cmat),] #drop intercept
rgy = range(cmat)
cpar = log(1/grid)
plot(range(cpar),rgy,type='n',xlab='log(1/lambda)',ylab='coeficients',cex.lab=1.5)
for(i in 1:nrow(cmat)) lines(cpar,cmat[i,],col=i+1,type='l')
##  Try Cross validation using cv.glmnet
set.seed(80)
cv.out = cv.glmnet(x,y,alpha=1,lambda=grid)
cmp = log(1/cv.out$lambda)
plot(cmp,cv.out$cvm,type='b',xlab='cmp = log(1/lambda)',cex.lab=1.5)
bestlam = cv.out$lambda.min
bestcmp = log(1/bestlam)
text(bestcmp,160000,paste('best lambda is: ',round(bestlam,2)),col='red',cex=1.5)
abline(v=bestcmp,col='red')
##get coefficients for best lambda
bestlassocoef = predict(lasso.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
rgxy = 1.1*range(c(lm.mod$coeficients,bestridgecoef,bestlassocoef))
##get coefficients for best lambda
bestlassocoef = predict(lasso.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
ddf = data.frame(x,y)
lm.mod = lm(y~.,ddf)
rgxy = 1.1*range(c(lm.mod$coeficients,bestridgecoef,bestlassocoef))
print(bestlassocoef)
##get fits
lasso.fit = predict(lasso.mod,s=bestlam,newx=x)
fmat = cbind(y,lm.fit,ridge.fit,lasso.fit)
##get coefficients for best lambda
bestridgecoef = predict(ridge.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
## Fit ridge on grid of lambda values.
gsize=100
grid=5^seq(10,-2,length=gsize)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid,standardize=FALSE)  #I already standardized
## plot coefficients
cmat = coef(ridge.mod)
cmat = cmat[2:nrow(cmat),] #drop intercept
rgy = range(cmat)
cpar = log(1/grid)
plot(range(cpar),rgy,type='n',xlab='log(1/lambda)',ylab='coeficients',cex.lab=1.5)
for(i in 1:nrow(cmat)) lines(cpar,cmat[i,],col=i+1,type='l')
##  Try Cross validation using cv.glmnet
set.seed(14)
cv.out = cv.glmnet(x,y,alpha=0,lambda=grid)
cmp = log(1/cv.out$lambda)
plot(cmp,cv.out$cvm,type='b',xlab='cmp = log(1/lambda)',cex.lab=1.5)
bestlam = cv.out$lambda.min
bestcmp = log(1/bestlam)
text(bestcmp,160000,paste('best lambda is: ',round(bestlam,2)),col='red',cex=1.5)
abline(v=bestcmp,col='red')
##get coefficients for best lambda
bestridgecoef = predict(ridge.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
ddf = data.frame(x,y)
lm.mod = lm(y~.,ddf)
rgxy = range(c(lm.mod$coeficients,bestridgecoef))
plot(lm.mod$coef,bestridgecoef,xlim=rgxy,ylim=rgxy,xlab='linear coefficients',ylab='ridge coefficients')
abline(0,1,col='red',lty=2)
abline(v=0,lty=3)
abline(h=0,lty=3)
##get fits
ridge.fit = predict(ridge.mod,s=bestlam,newx=x)
lm.fit = lm.mod$fitted
fmat = cbind(y,lm.fit,ridge.fit)
colnames(fmat) = c('y','linear','ridge')
pairs(fmat)
##get coefficients for best lambda
bestlassocoef = predict(lasso.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
ddf = data.frame(x,y)
lm.mod = lm(y~.,ddf)
rgxy = range(c(lm.mod$coeficients,bestlassocoef))
plot(lm.mod$coef,bestlassocoef,xlim=rgxy,ylim=rgxy,xlab='linear coefficients',ylab='lasso coefficients')
abline(0,1,col='red',lty=2)
abline(v=0,lty=3)
abline(h=0,lty=3)
print(bestlassocoef)
knitr::opts_chunk$set(echo = TRUE)
cd = read.csv("http://www.rob-mcculloch.org/data/usedcars.csv")
print(dim(cd))
head(cd)
library(glmnet)
#dummy up the categorical variables
cd$trim=as.factor(cd$trim)
cd$isOneOwner=as.factor(cd$isOneOwner)
cd$color=as.factor(cd$color)
cd$displacement=as.factor(cd$displacement)
cd$fuel=as.factor(cd$fuel)
cd$region=as.factor(cd$region)
cd$soundSystem=as.factor(cd$soundSystem)
cd$wheelType=as.factor(cd$wheelType)
summary(cd)
## Get the model matrix (x) and log price (y)
x=model.matrix(log(price)~.,cd)[,-1]
x=scale(x) #let's scale the data to start with so we an interpret stuff.
y=log(cd$price)
print(dim(x))
print(colnames(x))
## do lasso (alpha=1)
gsize=100
grid=5^seq(10,-2,length=gsize)
lasso.mod=glmnet(x,y,alpha=1,lambda=grid,standardize=FALSE)
## plot coefficients
cmat = coef(lasso.mod)
cmat = cmat[2:nrow(cmat),] #drop intercept
rgy = range(cmat)
cpar = log(1/grid)
plot(range(cpar),rgy,type='n',xlab='log(1/lambda)',ylab='coeficients',cex.lab=1.5)
for(i in 1:nrow(cmat)) lines(cpar,cmat[i,],col=i+1,type='l')
##  Try Cross validation using cv.glmnet
set.seed(80)
cv.out = cv.glmnet(x,y,alpha=1,lambda=grid)
cmp = log(1/cv.out$lambda)
plot(cmp,cv.out$cvm,type='b',xlab='cmp = log(1/lambda)',cex.lab=1.5)
bestlam = cv.out$lambda.min
bestcmp = log(1/bestlam)
text(bestcmp,160000,paste('best lambda is: ',round(bestlam,2)),col='red',cex=1.5)
abline(v=bestcmp,col='red')
##get coefficients for best lambda
bestlassocoef = predict(lasso.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
ddf = data.frame(x,y)
lm.mod = lm(y~.,ddf)
rgxy = range(c(lm.mod$coeficients,bestlassocoef))
plot(lm.mod$coef,bestlassocoef,xlim=rgxy,ylim=rgxy,xlab='linear coefficients',ylab='lasso coefficients')
abline(0,1,col='red',lty=2)
abline(v=0,lty=3)
abline(h=0,lty=3)
print(bestlassocoef)
##get fits
lasso.fit = predict(lasso.mod,s=bestlam,newx=x)
lm.fit = lm.mod$fitted
fmat = cbind(y,lm.fit,lasso.fit)
colnames(fmat) = c('y','linear','lasso')
pairs(fmat)
## Fit ridge on grid of lambda values.
gsize=100
grid=5^seq(10,-2,length=gsize)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid,standardize=FALSE)  #I already standardized
## plot coefficients
cmat = coef(ridge.mod)
cmat = cmat[2:nrow(cmat),] #drop intercept
rgy = range(cmat)
cpar = log(1/grid)
plot(range(cpar),rgy,type='n',xlab='log(1/lambda)',ylab='coeficients',cex.lab=1.5)
for(i in 1:nrow(cmat)) lines(cpar,cmat[i,],col=i+1,type='l')
##  Try Cross validation using cv.glmnet
set.seed(14)
cv.out = cv.glmnet(x,y,alpha=0,lambda=grid)
cmp = log(1/cv.out$lambda)
plot(cmp,cv.out$cvm,type='b',xlab='cmp = log(1/lambda)',cex.lab=1.5)
bestlam = cv.out$lambda.min
bestcmp = log(1/bestlam)
text(bestcmp,160000,paste('best lambda is: ',round(bestlam,2)),col='red',cex=1.5)
abline(v=bestcmp,col='red')
##get coefficients for best lambda
bestridgecoef = predict(ridge.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
rgxy = 1.1*range(c(lm.mod$coeficients,bestridgecoef,bestlassocoef))
plot(lm.mod$coef,bestridgecoef,xlim=rgxy,ylim=rgxy,xlab='linear coefficients',ylab='ridge-lasso coefficients',col='green',pch=2,cex.lab=1.5)
points(lm.mod$coef,bestlassocoef,col='blue',pch=19)
abline(0,1,col='red',lty=2)
abline(v=0,lty=3)
abline(h=0,lty=3)
legend('topleft',legend=c('ridge','lasso'),pch=19,col=c('green','blue'))
##get fits
ridge.fit = predict(ridge.mod,s=bestlam,newx=x)
fmat = cbind(y,lm.fit,ridge.fit,lasso.fit)
colnames(fmat) = c('y','linear','ridge','lasso')
pairs(fmat)
knitr::opts_chunk$set(echo = TRUE)
cd = read.csv("http://www.rob-mcculloch.org/data/usedcars.csv")
print(dim(cd))
head(cd)
library(glmnet)
#dummy up the categorical variables
cd$trim=as.factor(cd$trim)
cd$isOneOwner=as.factor(cd$isOneOwner)
cd$color=as.factor(cd$color)
cd$displacement=as.factor(cd$displacement)
cd$fuel=as.factor(cd$fuel)
cd$region=as.factor(cd$region)
cd$soundSystem=as.factor(cd$soundSystem)
cd$wheelType=as.factor(cd$wheelType)
summary(cd)
## Get the model matrix (x) and log price (y)
x=model.matrix(log(price)~.,cd)[,-1]
x=scale(x) #let's scale the data to start with so we an interpret stuff.
y=log(cd$price)
print(dim(x))
print(colnames(x))
## do lasso (alpha=1)
gsize=100
grid=5^seq(10,-2,length=gsize)
lasso.mod=glmnet(x,y,alpha=1,lambda=grid,standardize=FALSE)
## plot coefficients
cmat = coef(lasso.mod)
cmat = cmat[2:nrow(cmat),] #drop intercept
rgy = range(cmat)
cpar = log(1/grid)
plot(range(cpar),rgy,type='n',xlab='log(1/lambda)',ylab='coeficients',cex.lab=1.5)
for(i in 1:nrow(cmat)) lines(cpar,cmat[i,],col=i+1,type='l')
##  Try Cross validation using cv.glmnet
set.seed(80)
cv.out = cv.glmnet(x,y,alpha=1,lambda=grid)
cmp = log(1/cv.out$lambda)
plot(cmp,cv.out$cvm,type='b',xlab='cmp = log(1/lambda)',cex.lab=1.5)
bestlam = cv.out$lambda.min
bestcmp = log(1/bestlam)
text(bestcmp,160000,paste('best lambda is: ',round(bestlam,2)),col='red',cex=1.5)
abline(v=bestcmp,col='red')
print(bestlam)
##get coefficients for best lambda
bestlassocoef = predict(lasso.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
ddf = data.frame(x,y)
lm.mod = lm(y~.,ddf)
rgxy = range(c(lm.mod$coeficients,bestlassocoef))
plot(lm.mod$coef,bestlassocoef,xlim=rgxy,ylim=rgxy,xlab='linear coefficients',ylab='lasso coefficients')
abline(0,1,col='red',lty=2)
abline(v=0,lty=3)
abline(h=0,lty=3)
print(bestlassocoef)
##get fits
lasso.fit = predict(lasso.mod,s=bestlam,newx=x)
lm.fit = lm.mod$fitted
fmat = cbind(y,lm.fit,lasso.fit)
colnames(fmat) = c('y','linear','lasso')
pairs(fmat)
## Fit ridge on grid of lambda values.
gsize=100
grid=5^seq(10,-2,length=gsize)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid,standardize=FALSE)  #I already standardized
## plot coefficients
cmat = coef(ridge.mod)
cmat = cmat[2:nrow(cmat),] #drop intercept
rgy = range(cmat)
cpar = log(1/grid)
plot(range(cpar),rgy,type='n',xlab='log(1/lambda)',ylab='coeficients',cex.lab=1.5)
for(i in 1:nrow(cmat)) lines(cpar,cmat[i,],col=i+1,type='l')
##  Try Cross validation using cv.glmnet
set.seed(14)
cv.out = cv.glmnet(x,y,alpha=0,lambda=grid)
cmp = log(1/cv.out$lambda)
plot(cmp,cv.out$cvm,type='b',xlab='cmp = log(1/lambda)',cex.lab=1.5)
bestlam = cv.out$lambda.min
bestcmp = log(1/bestlam)
text(bestcmp,160000,paste('best lambda is: ',round(bestlam,2)),col='red',cex=1.5)
abline(v=bestcmp,col='red')
print(bestlam)
##get coefficients for best lambda
bestridgecoef = predict(ridge.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
rgxy = 1.1*range(c(lm.mod$coeficients,bestridgecoef,bestlassocoef))
plot(lm.mod$coef,bestridgecoef,xlim=rgxy,ylim=rgxy,xlab='linear coefficients',ylab='ridge-lasso coefficients',col='green',pch=2,cex.lab=1.5)
points(lm.mod$coef,bestlassocoef,col='blue',pch=19)
abline(0,1,col='red',lty=2)
abline(v=0,lty=3)
abline(h=0,lty=3)
legend('topleft',legend=c('ridge','lasso'),pch=19,col=c('green','blue'))
print(bestridgecoef)
##get fits
ridge.fit = predict(ridge.mod,s=bestlam,newx=x)
fmat = cbind(y,lm.fit,ridge.fit,lasso.fit)
colnames(fmat) = c('y','linear','ridge','lasso')
pairs(fmat)
##get coefficients for best lambda
bestlassocoef = predict(lasso.mod,s=bestlam,type='coefficients',exact=TRUE)[,1]
ddf = data.frame(x,y)
lm.mod = lm(y~.,ddf)
rgxy = range(c(lm.mod$coeficients,bestlassocoef))
plot(lm.mod$coef,bestlassocoef,xlim=rgxy,ylim=rgxy,xlab='linear coefficients',ylab='lasso coefficients')
abline(0,1,col='red',lty=2)
abline(v=0,lty=3)
abline(h=0,lty=3)
